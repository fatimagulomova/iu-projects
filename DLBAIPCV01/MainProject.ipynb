{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (8.1.7)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.2)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.16.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fatim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install opencv-python  # For video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights, fasterrcnn_resnet50_fpn, maskrcnn_resnet50_fpn, ssd300_vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO = 'video for project.mp4'\n",
    " \n",
    "# Save the output video file\n",
    "OUTPUT_VIDEO_YOLO_DET = 'video_obj_detect_yolo.mp4'\n",
    "OUTPUT_VIDEO_YOLO_SEG = 'video_obj_segementation_yolo.mp4'\n",
    "OUTPUT_VIDEO_FASTER_RCNN_DET = 'video_obj_detect_faster_rcnn.mp4'\n",
    "OUTPUT_VIDEO_FASTER_RCNN_SEG = 'video_obj_segmentation_faster_rcnn.mp4'\n",
    "OUTPUT_VIDEO_SSD_DET = 'video_obj_detect_ssd.mp4'\n",
    "OUTPUT_VIDEO_SSD_SEG = 'video_obj_segmentation_ssd.mp4'\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "COCO_NAMES = [\"person\" , \"bicycle\" , \"car\" , \"motorcycle\" , \"airplane\" , \"bus\" , \"train\" , \"truck\" , \"boat\" , \"traffic light\" , \"fire hydrant\" , \"street sign\" , \n",
    "              \"stop sign\" , \"parking meter\" , \"bench\" , \"bird\" , \"cat\" , \"dog\" , \"horse\" , \"sheep\" , \"cow\" , \"elephant\" , \"bear\" , \"zebra\" , \"giraffe\" , \"hat\" , \"backpack\" , \n",
    "              \"umbrella\" , \"shoe\" , \"eye glasses\" , \"handbag\" , \"tie\" , \"suitcase\" , \"frisbee\" , \"skis\" , \"snowboard\" , \"sports ball\" , \"kite\" , \"baseball bat\" , \"baseball glove\" , \n",
    "              \"skateboard\" , \"surfboard\" , \"tennis racket\" , \"bottle\" , \"plate\" , \"wine glass\" , \"cup\" , \"fork\" , \"knife\" , \"spoon\" , \"bowl\" , \"banana\" , \"apple\" , \"sandwich\" , \n",
    "              \"orange\" , \"broccoli\" , \"carrot\" , \"hot dog\" ,\"pizza\" , \"donut\" , \"cake\" , \"chair\" , \"couch\" , \"potted plant\" , \"bed\" ,\"mirror\" , \"dining table\" , \"window\" , \"desk\" , \n",
    "              \"toilet\" , \"door\" , \"tv\" , \"laptop\" , \"mouse\" , \"remote\" , \"keyboard\" , \"cell phone\" , \"microwave\" ,\"oven\" , \"toaster\" , \"sink\" , \"refrigerator\" , \"blender\" , \"book\" ,\n",
    "              \"clock\" , \"vase\" , \"scissors\" , \"teddy bear\" , \"hair drier\" , \"toothbrush\" , \"hair brush\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 1 car, 163.5ms\n",
      "Speed: 21.7ms preprocess, 163.5ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 145.8ms\n",
      "Speed: 0.0ms preprocess, 145.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 151.1ms\n",
      "Speed: 3.4ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 119.3ms\n",
      "Speed: 2.7ms preprocess, 119.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 103.6ms\n",
      "Speed: 0.0ms preprocess, 103.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 78.1ms\n",
      "Speed: 15.6ms preprocess, 78.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 109.7ms\n",
      "Speed: 0.0ms preprocess, 109.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 83.3ms\n",
      "Speed: 4.1ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 109.6ms\n",
      "Speed: 0.0ms preprocess, 109.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 98.7ms\n",
      "Speed: 0.0ms preprocess, 98.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 102.0ms\n",
      "Speed: 0.0ms preprocess, 102.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 108.1ms\n",
      "Speed: 0.0ms preprocess, 108.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 107.0ms\n",
      "Speed: 4.1ms preprocess, 107.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 100.0ms\n",
      "Speed: 2.8ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 98.9ms\n",
      "Speed: 4.7ms preprocess, 98.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 95.5ms\n",
      "Speed: 0.0ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 120.2ms\n",
      "Speed: 4.1ms preprocess, 120.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 111.4ms\n",
      "Speed: 6.7ms preprocess, 111.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 113.9ms\n",
      "Speed: 2.1ms preprocess, 113.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 119.8ms\n",
      "Speed: 3.1ms preprocess, 119.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 97.8ms\n",
      "Speed: 1.5ms preprocess, 97.8ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 167.3ms\n",
      "Speed: 0.0ms preprocess, 167.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 97.2ms\n",
      "Speed: 0.0ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 135.4ms\n",
      "Speed: 0.0ms preprocess, 135.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 117.1ms\n",
      "Speed: 9.4ms preprocess, 117.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 140.6ms\n",
      "Speed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 99.7ms\n",
      "Speed: 2.0ms preprocess, 99.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 89.0ms\n",
      "Speed: 0.0ms preprocess, 89.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 105.3ms\n",
      "Speed: 0.0ms preprocess, 105.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 127.2ms\n",
      "Speed: 0.0ms preprocess, 127.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 101.8ms\n",
      "Speed: 0.0ms preprocess, 101.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 102.3ms\n",
      "Speed: 1.1ms preprocess, 102.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 117.1ms\n",
      "Speed: 0.0ms preprocess, 117.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 105.8ms\n",
      "Speed: 1.9ms preprocess, 105.8ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 117.8ms\n",
      "Speed: 4.3ms preprocess, 117.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 114.3ms\n",
      "Speed: 0.0ms preprocess, 114.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 114.7ms\n",
      "Speed: 0.0ms preprocess, 114.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 167.8ms\n",
      "Speed: 1.1ms preprocess, 167.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 117.4ms\n",
      "Speed: 0.0ms preprocess, 117.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 89.1ms\n",
      "Speed: 1.3ms preprocess, 89.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 119.1ms\n",
      "Speed: 3.0ms preprocess, 119.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 78.9ms\n",
      "Speed: 0.0ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 78.1ms\n",
      "Speed: 15.6ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 97.7ms\n",
      "Speed: 0.0ms preprocess, 97.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 129.7ms\n",
      "Speed: 0.0ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 112.0ms\n",
      "Speed: 18.1ms preprocess, 112.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 115.8ms\n",
      "Speed: 6.2ms preprocess, 115.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 101.0ms\n",
      "Speed: 5.6ms preprocess, 101.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 88.3ms\n",
      "Speed: 0.0ms preprocess, 88.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 107.2ms\n",
      "Speed: 3.5ms preprocess, 107.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 105.7ms\n",
      "Speed: 2.0ms preprocess, 105.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 99.8ms\n",
      "Speed: 8.9ms preprocess, 99.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 106.7ms\n",
      "Speed: 0.0ms preprocess, 106.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 125.8ms\n",
      "Speed: 15.6ms preprocess, 125.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 116.9ms\n",
      "Speed: 15.6ms preprocess, 116.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 114.7ms\n",
      "Speed: 0.0ms preprocess, 114.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 140.6ms\n",
      "Speed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 85.5ms\n",
      "Speed: 3.1ms preprocess, 85.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 110.6ms\n",
      "Speed: 0.0ms preprocess, 110.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 95.8ms\n",
      "Speed: 8.5ms preprocess, 95.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 88.1ms\n",
      "Speed: 0.0ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 99.6ms\n",
      "Speed: 1.0ms preprocess, 99.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 96.7ms\n",
      "Speed: 0.0ms preprocess, 96.7ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 120.6ms\n",
      "Speed: 0.0ms preprocess, 120.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 122.4ms\n",
      "Speed: 8.0ms preprocess, 122.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 86.0ms\n",
      "Speed: 3.7ms preprocess, 86.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 94.6ms\n",
      "Speed: 2.1ms preprocess, 94.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 100.4ms\n",
      "Speed: 0.0ms preprocess, 100.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 98.1ms\n",
      "Speed: 3.1ms preprocess, 98.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 110.3ms\n",
      "Speed: 6.8ms preprocess, 110.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 106.0ms\n",
      "Speed: 0.0ms preprocess, 106.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 101.7ms\n",
      "Speed: 0.0ms preprocess, 101.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 114.5ms\n",
      "Speed: 0.0ms preprocess, 114.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 102.1ms\n",
      "Speed: 0.0ms preprocess, 102.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 motorcycle, 96.1ms\n",
      "Speed: 3.3ms preprocess, 96.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 111.3ms\n",
      "Speed: 0.0ms preprocess, 111.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 94.3ms\n",
      "Speed: 0.0ms preprocess, 94.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 70.2ms\n",
      "Speed: 3.3ms preprocess, 70.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 78.1ms\n",
      "Speed: 15.6ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 93.8ms\n",
      "Speed: 0.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 78.1ms\n",
      "Speed: 15.6ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 79.7ms\n",
      "Speed: 0.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 105.4ms\n",
      "Speed: 3.1ms preprocess, 105.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 95.0ms\n",
      "Speed: 0.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 125.3ms\n",
      "Speed: 0.0ms preprocess, 125.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 101.3ms\n",
      "Speed: 0.0ms preprocess, 101.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 157.0ms\n",
      "Speed: 0.0ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 94.6ms\n",
      "Speed: 0.0ms preprocess, 94.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 109.6ms\n",
      "Speed: 0.0ms preprocess, 109.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 100.2ms\n",
      "Speed: 2.0ms preprocess, 100.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 109.4ms\n",
      "Speed: 15.6ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 75.0ms\n",
      "Speed: 1.0ms preprocess, 75.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 94.0ms\n",
      "Speed: 2.1ms preprocess, 94.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 97.6ms\n",
      "Speed: 0.0ms preprocess, 97.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 118.1ms\n",
      "Speed: 0.0ms preprocess, 118.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 116.1ms\n",
      "Speed: 0.0ms preprocess, 116.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 109.7ms\n",
      "Speed: 0.0ms preprocess, 109.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 102.1ms\n",
      "Speed: 0.0ms preprocess, 102.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 107.1ms\n",
      "Speed: 0.0ms preprocess, 107.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 104.5ms\n",
      "Speed: 12.9ms preprocess, 104.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 113.0ms\n",
      "Speed: 0.0ms preprocess, 113.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 95.5ms\n",
      "Speed: 10.6ms preprocess, 95.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 78.1ms\n",
      "Speed: 0.0ms preprocess, 78.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 101.2ms\n",
      "Speed: 0.0ms preprocess, 101.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 103.7ms\n",
      "Speed: 13.0ms preprocess, 103.7ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No frame...\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 127.6ms\n",
      "Speed: 0.0ms preprocess, 127.6ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 173.0ms\n",
      "Speed: 0.0ms preprocess, 173.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 140.6ms\n",
      "Speed: 0.0ms preprocess, 140.6ms inference, 34.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 124.9ms\n",
      "Speed: 0.0ms preprocess, 124.9ms inference, 31.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 137.8ms\n",
      "Speed: 0.0ms preprocess, 137.8ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 93.7ms\n",
      "Speed: 0.0ms preprocess, 93.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 93.8ms\n",
      "Speed: 0.0ms preprocess, 93.8ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 112.0ms\n",
      "Speed: 15.6ms preprocess, 112.0ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 118.2ms\n",
      "Speed: 8.0ms preprocess, 118.2ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.3ms\n",
      "Speed: 15.6ms preprocess, 109.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 125.5ms\n",
      "Speed: 0.0ms preprocess, 125.5ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 122.7ms\n",
      "Speed: 15.6ms preprocess, 122.7ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 107.2ms\n",
      "Speed: 1.0ms preprocess, 107.2ms inference, 31.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 140.6ms\n",
      "Speed: 0.0ms preprocess, 140.6ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 27.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 143.2ms\n",
      "Speed: 0.0ms preprocess, 143.2ms inference, 33.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 132.2ms\n",
      "Speed: 0.0ms preprocess, 132.2ms inference, 33.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 132.1ms\n",
      "Speed: 2.6ms preprocess, 132.1ms inference, 33.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 174.4ms\n",
      "Speed: 0.0ms preprocess, 174.4ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 229.9ms\n",
      "Speed: 0.0ms preprocess, 229.9ms inference, 50.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 269.5ms\n",
      "Speed: 1.5ms preprocess, 269.5ms inference, 38.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 118.3ms\n",
      "Speed: 8.0ms preprocess, 118.3ms inference, 40.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 153.4ms\n",
      "Speed: 3.3ms preprocess, 153.4ms inference, 31.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 136.7ms\n",
      "Speed: 10.4ms preprocess, 136.7ms inference, 31.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 131.3ms\n",
      "Speed: 0.0ms preprocess, 131.3ms inference, 40.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 167.9ms\n",
      "Speed: 2.3ms preprocess, 167.9ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 172.3ms\n",
      "Speed: 0.0ms preprocess, 172.3ms inference, 27.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 125.4ms\n",
      "Speed: 1.4ms preprocess, 125.4ms inference, 32.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 100.0ms\n",
      "Speed: 15.9ms preprocess, 100.0ms inference, 34.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 110.4ms\n",
      "Speed: 8.6ms preprocess, 110.4ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 163.2ms\n",
      "Speed: 0.0ms preprocess, 163.2ms inference, 82.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 169.6ms\n",
      "Speed: 0.0ms preprocess, 169.6ms inference, 25.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 truck, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 37.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 138.5ms\n",
      "Speed: 0.0ms preprocess, 138.5ms inference, 34.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 128.3ms\n",
      "Speed: 3.8ms preprocess, 128.3ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 145.7ms\n",
      "Speed: 5.0ms preprocess, 145.7ms inference, 33.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 157.8ms\n",
      "Speed: 0.0ms preprocess, 157.8ms inference, 24.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 110.3ms\n",
      "Speed: 0.0ms preprocess, 110.3ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 107.7ms\n",
      "Speed: 17.3ms preprocess, 107.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 136.4ms\n",
      "Speed: 0.0ms preprocess, 136.4ms inference, 36.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 135.5ms\n",
      "Speed: 15.9ms preprocess, 135.5ms inference, 36.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 137.7ms\n",
      "Speed: 0.0ms preprocess, 137.7ms inference, 41.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 98.0ms\n",
      "Speed: 10.0ms preprocess, 98.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 140.2ms\n",
      "Speed: 8.0ms preprocess, 140.2ms inference, 40.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 128.2ms\n",
      "Speed: 0.0ms preprocess, 128.2ms inference, 42.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 123.1ms\n",
      "Speed: 0.0ms preprocess, 123.1ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 125.4ms\n",
      "Speed: 15.6ms preprocess, 125.4ms inference, 29.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 149.5ms\n",
      "Speed: 0.0ms preprocess, 149.5ms inference, 32.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 134.9ms\n",
      "Speed: 13.5ms preprocess, 134.9ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 110.3ms\n",
      "Speed: 0.0ms preprocess, 110.3ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 93.7ms\n",
      "Speed: 15.6ms preprocess, 93.7ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 120.9ms\n",
      "Speed: 15.6ms preprocess, 120.9ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 143.2ms\n",
      "Speed: 0.0ms preprocess, 143.2ms inference, 32.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 149.5ms\n",
      "Speed: 0.0ms preprocess, 149.5ms inference, 23.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 134.7ms\n",
      "Speed: 8.0ms preprocess, 134.7ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 141.6ms\n",
      "Speed: 0.0ms preprocess, 141.6ms inference, 24.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 128.8ms\n",
      "Speed: 0.0ms preprocess, 128.8ms inference, 30.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 115.3ms\n",
      "Speed: 0.0ms preprocess, 115.3ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 109.3ms\n",
      "Speed: 15.6ms preprocess, 109.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 138.2ms\n",
      "Speed: 2.0ms preprocess, 138.2ms inference, 34.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 125.4ms\n",
      "Speed: 2.8ms preprocess, 125.4ms inference, 41.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 124.2ms\n",
      "Speed: 4.0ms preprocess, 124.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 124.5ms\n",
      "Speed: 0.0ms preprocess, 124.5ms inference, 32.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 133.4ms\n",
      "Speed: 1.7ms preprocess, 133.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 134.8ms\n",
      "Speed: 0.0ms preprocess, 134.8ms inference, 31.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 166.3ms\n",
      "Speed: 3.7ms preprocess, 166.3ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 135.2ms\n",
      "Speed: 0.0ms preprocess, 135.2ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 153.5ms\n",
      "Speed: 6.2ms preprocess, 153.5ms inference, 29.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 117.2ms\n",
      "Speed: 1.0ms preprocess, 117.2ms inference, 47.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 151.8ms\n",
      "Speed: 0.0ms preprocess, 151.8ms inference, 33.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 30.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 192.9ms\n",
      "Speed: 0.0ms preprocess, 192.9ms inference, 31.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 105.4ms\n",
      "Speed: 15.6ms preprocess, 105.4ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 124.4ms\n",
      "Speed: 2.1ms preprocess, 124.4ms inference, 65.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 156.5ms\n",
      "Speed: 15.6ms preprocess, 156.5ms inference, 62.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 212.0ms\n",
      "Speed: 0.0ms preprocess, 212.0ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 122.3ms\n",
      "Speed: 2.0ms preprocess, 122.3ms inference, 45.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 motorcycle, 147.5ms\n",
      "Speed: 6.7ms preprocess, 147.5ms inference, 45.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 motorcycle, 142.2ms\n",
      "Speed: 0.0ms preprocess, 142.2ms inference, 32.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 152.8ms\n",
      "Speed: 0.0ms preprocess, 152.8ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 166.7ms\n",
      "Speed: 0.0ms preprocess, 166.7ms inference, 33.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 114.2ms\n",
      "Speed: 15.6ms preprocess, 114.2ms inference, 26.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 109.3ms\n",
      "Speed: 0.0ms preprocess, 109.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 148.6ms\n",
      "Speed: 0.0ms preprocess, 148.6ms inference, 42.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 145.9ms\n",
      "Speed: 0.0ms preprocess, 145.9ms inference, 38.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 113.7ms\n",
      "Speed: 5.1ms preprocess, 113.7ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 125.0ms\n",
      "Speed: 0.0ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 166.2ms\n",
      "Speed: 0.0ms preprocess, 166.2ms inference, 33.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 150.0ms\n",
      "Speed: 0.0ms preprocess, 150.0ms inference, 33.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 131.3ms\n",
      "Speed: 3.3ms preprocess, 131.3ms inference, 32.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 167.9ms\n",
      "Speed: 0.0ms preprocess, 167.9ms inference, 33.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 141.4ms\n",
      "Speed: 8.0ms preprocess, 141.4ms inference, 33.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 117.3ms\n",
      "Speed: 3.1ms preprocess, 117.3ms inference, 22.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 122.2ms\n",
      "Speed: 9.8ms preprocess, 122.2ms inference, 42.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 179.8ms\n",
      "Speed: 0.0ms preprocess, 179.8ms inference, 33.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 119.1ms\n",
      "Speed: 0.0ms preprocess, 119.1ms inference, 29.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 132.3ms\n",
      "Speed: 7.2ms preprocess, 132.3ms inference, 47.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 150.4ms\n",
      "Speed: 0.0ms preprocess, 150.4ms inference, 24.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 203.0ms\n",
      "Speed: 0.0ms preprocess, 203.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 123.0ms\n",
      "Speed: 0.0ms preprocess, 123.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 144.0ms\n",
      "Speed: 0.0ms preprocess, 144.0ms inference, 28.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 141.3ms\n",
      "Speed: 0.0ms preprocess, 141.3ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 147.9ms\n",
      "Speed: 15.6ms preprocess, 147.9ms inference, 32.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 120.4ms\n",
      "Speed: 0.0ms preprocess, 120.4ms inference, 30.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 122.2ms\n",
      "Speed: 8.0ms preprocess, 122.2ms inference, 35.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 120.9ms\n",
      "Speed: 4.0ms preprocess, 120.9ms inference, 34.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 132.8ms\n",
      "Speed: 5.1ms preprocess, 132.8ms inference, 54.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 117.6ms\n",
      "Speed: 0.0ms preprocess, 117.6ms inference, 32.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 147.7ms\n",
      "Speed: 0.0ms preprocess, 147.7ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 160.7ms\n",
      "Speed: 0.0ms preprocess, 160.7ms inference, 36.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 143.4ms\n",
      "Speed: 8.0ms preprocess, 143.4ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 154.5ms\n",
      "Speed: 0.0ms preprocess, 154.5ms inference, 23.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 110.3ms\n",
      "Speed: 0.0ms preprocess, 110.3ms inference, 31.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 145.8ms\n",
      "Speed: 0.0ms preprocess, 145.8ms inference, 35.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 136.1ms\n",
      "Speed: 15.0ms preprocess, 136.1ms inference, 38.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 145.9ms\n",
      "Speed: 4.3ms preprocess, 145.9ms inference, 37.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 119.2ms\n",
      "Speed: 0.0ms preprocess, 119.2ms inference, 31.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 162.2ms\n",
      "Speed: 6.1ms preprocess, 162.2ms inference, 31.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 150.5ms\n",
      "Speed: 0.0ms preprocess, 150.5ms inference, 34.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 150.4ms\n",
      "Speed: 0.0ms preprocess, 150.4ms inference, 35.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 135.5ms\n",
      "Speed: 0.0ms preprocess, 135.5ms inference, 31.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 203.5ms\n",
      "Speed: 0.0ms preprocess, 203.5ms inference, 85.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 148.7ms\n",
      "Speed: 0.0ms preprocess, 148.7ms inference, 24.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 144.6ms\n",
      "Speed: 0.0ms preprocess, 144.6ms inference, 38.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 166.6ms\n",
      "Speed: 3.5ms preprocess, 166.6ms inference, 41.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 165.9ms\n",
      "Speed: 8.0ms preprocess, 165.9ms inference, 41.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No frame...\n"
     ]
    }
   ],
   "source": [
    "def run_model(model, video, output_video):\n",
    "    model = model\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    # Create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    # Get frame width and height\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_video, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"No frame...\")\n",
    "            break\n",
    "\n",
    "        # Predict on image\n",
    "        results = model.track(source=frame, persist=True, tracker='bytetrack.yaml')\n",
    "        frame = results[0].plot()\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(frame)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow(\"ObjectDetection\", frame)\n",
    "\n",
    "        # Terminate run when \"Q\" pressed\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "\n",
    "    # Release the video recording\n",
    "    # out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Object Detection\n",
    "run_model(model=YOLO('yolov8n.pt', \"v8\"), video=VIDEO, output_video=OUTPUT_VIDEO_YOLO_DET)\n",
    "\n",
    "# Object Segmentation\n",
    "run_model(model=YOLO('yolov8n-seg.pt', \"v8\"), video=VIDEO, output_video=OUTPUT_VIDEO_YOLO_SEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frame...\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    # Load a pre-trained Faster R-CNN model    \n",
    "    weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "    model = fasterrcnn_resnet50_fpn(weights=weights, pretrained=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def faster_rcnn_object_detection(model, frame):\n",
    "    # Transform frame to tensor and add batch dimension\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    frame_tensor = transform(frame).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(frame_tensor)\n",
    "\n",
    "    bboxes, labels, scores = prediction[0][\"boxes\"], prediction[0][\"labels\"], prediction[0][\"scores\"]\n",
    "\n",
    "    # num = torch.argwhere(scores > 0.9).shape[0]\n",
    "\n",
    "    # Draw boxes and labels on the frame\n",
    "    for i in range(len(prediction[0]['boxes'])):\n",
    "        xmin, ymin, xmax, ymax = bboxes[i].numpy().astype('int')\n",
    "        class_name = COCO_NAMES[labels.numpy()[i] -1]\n",
    "        \n",
    "        if scores[i] > 0.9:  # Only draw boxes for confident predictions\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 3)\n",
    "            \n",
    "            # Put label\n",
    "            label = f\"{class_name}: {scores[i]:.2f}\"\n",
    "            cv2.putText(frame, label, (xmin, ymin - 10), FONT, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Set up the model\n",
    "model = get_model()\n",
    "\n",
    "# Video capture setup\n",
    "cap = cv2.VideoCapture(VIDEO)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Get frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_FASTER_RCNN_DET, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"No frame...\")\n",
    "        break\n",
    "\n",
    "    # Process frame\n",
    "    processed_frame = faster_rcnn_object_detection(model, frame)\n",
    "    \n",
    "    # Write the processed frame to output\n",
    "    out.write(processed_frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', processed_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Segementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frame...\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained Mask R-CNN model\n",
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Function to overlay masks and draw rectangles and labels on the frame\n",
    "def faster_rcnn_object_segmentation(frame, threshold=0.9):\n",
    "    # Function to preprocess the frame\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    frame_tensor = transform(frame).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(frame_tensor)\n",
    "    \n",
    "    labels = predictions[0]['labels'].cpu().numpy()\n",
    "    masks = predictions[0]['masks'].cpu().numpy()\n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "    \n",
    "    overlay = frame.copy()\n",
    "    \n",
    "    for i in range(len(masks)):\n",
    "        if scores[i] > threshold:\n",
    "            mask = masks[i, 0]\n",
    "            mask = (mask > 0.6).astype(np.uint8)\n",
    "            color = np.random.randint(0, 255, (3,), dtype=np.uint8)\n",
    "            overlay[mask == 1] = frame[mask == 1] * 0.5 + color * 0.5\n",
    "\n",
    "            xmin, ymin, xmax, ymax = boxes[i].astype('int')\n",
    "            class_name = COCO_NAMES[labels[i] - 1]\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(overlay, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            \n",
    "            # Put label\n",
    "            label = f\"{class_name}: {scores[i]:.2f}\"\n",
    "            cv2.putText(overlay, label, (xmin, ymin - 10), FONT, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "# Capture video\n",
    "cap = cv2.VideoCapture(VIDEO)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Get frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_FASTER_RCNN_SEG, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"No frame...\")\n",
    "        break\n",
    "\n",
    "    # Overlay masks\n",
    "    processed_frame = faster_rcnn_object_segmentation(frame)\n",
    "\n",
    "    # Write the processed frame to output\n",
    "    out.write(processed_frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', processed_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD (Single Shot Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatim\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frame...\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained SSD model\n",
    "model = ssd300_vgg16(pretrained=True)\n",
    "model.eval() \n",
    "\n",
    "def ssd_object_detection(frame, threshold=0.5):\n",
    "    # Function to preprocess the frame\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    frame_tensor = transform(frame).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(frame_tensor)\n",
    "    \n",
    "    labels = predictions[0]['labels'].cpu().numpy()\n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > threshold:\n",
    "\n",
    "            xmin, ymin, xmax, ymax = boxes[i].astype('int')\n",
    "            class_name = COCO_NAMES[labels[i] - 1]\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            \n",
    "            # Put label\n",
    "            label = f\"{class_name}: {scores[i]:.2f}\"\n",
    "            cv2.putText(frame, label, (xmin, ymin - 10), FONT, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Capture video\n",
    "cap = cv2.VideoCapture(VIDEO)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Get frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_SSD_DET, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"No frame...\")\n",
    "        break\n",
    "\n",
    "    # Overlay masks\n",
    "    processed_frame = ssd_object_detection(frame)\n",
    "\n",
    "    # Write the processed frame to output\n",
    "    out.write(processed_frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', processed_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frame...\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained SSD model\n",
    "model = ssd300_vgg16(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "def ssd_object_segmentation(frame, threshold=0.5):\n",
    "    # Function to preprocess the frame\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    frame_tensor = transform(frame).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(frame_tensor)\n",
    "\n",
    "    labels = predictions[0]['labels'].cpu().numpy()\n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > threshold:\n",
    "            xmin, ymin, xmax, ymax = boxes[i].astype('int')\n",
    "            class_name = COCO_NAMES[labels[i] - 1]\n",
    "\n",
    "            # Extract the detected object from the frame\n",
    "            object_segment = frame[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            # Convert to grayscale and threshold to create a mask\n",
    "            gray = cv2.cvtColor(object_segment, cv2.COLOR_BGR2GRAY)\n",
    "            _, mask = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Draw the contours on the original frame\n",
    "            cv2.drawContours(frame[ymin:ymax, xmin:xmax], contours, -1, (0, 255, 0), thickness=cv2.FILLED)\n",
    "\n",
    "            # Put label above the box\n",
    "            label = f\"{class_name}: {scores[i]:.2f}\"\n",
    "            cv2.putText(frame, label, (xmin, ymin - 10), FONT, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "# Capture video\n",
    "cap = cv2.VideoCapture(VIDEO)  # replace with actual video file path\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Get frame width and height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_SSD_SEG, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"No frame...\")\n",
    "        break\n",
    "\n",
    "    # Overlay segmentation masks\n",
    "    processed_frame = ssd_object_segmentation(frame)\n",
    "\n",
    "    # Write the processed frame to output\n",
    "    out.write(processed_frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', processed_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything once finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "yolo_model = YOLO('yolov8n.pt', \"v8\")\n",
    "faster_rccn_model = maskrcnn_resnet50_fpn(pretrained=True).eval()\n",
    "ssd_model = ssd300_vgg16(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Time (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame, model_type):\n",
    "    if model_type == 'yolo':\n",
    "        return frame  # Assuming YOLO model can take the frame directly\n",
    "    else:\n",
    "        transform = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((300, 300)),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        return transform(frame)\n",
    "\n",
    "\n",
    "def measure_performance(model, frames, model_type):\n",
    "    times = []\n",
    "    for frame in frames:\n",
    "        frame_tensor = preprocess_frame(frame, model_type)\n",
    "        if model_type != 'yolo':\n",
    "            frame_tensor = frame_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            if model_type == 'yolo':\n",
    "                results = model(frame)\n",
    "            else:\n",
    "                results = model(frame_tensor)\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    avg_time = sum(times) / len(times)\n",
    "    return avg_time, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 8 persons, 3 cars, 117.4ms\n",
      "Speed: 0.0ms preprocess, 117.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 127.0ms\n",
      "Speed: 2.0ms preprocess, 127.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 156.5ms\n",
      "Speed: 0.0ms preprocess, 156.5ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 159.8ms\n",
      "Speed: 0.0ms preprocess, 159.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 139.9ms\n",
      "Speed: 0.0ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 147.5ms\n",
      "Speed: 0.0ms preprocess, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 116.0ms\n",
      "Speed: 0.0ms preprocess, 116.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 truck, 120.3ms\n",
      "Speed: 0.0ms preprocess, 120.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 truck, 117.1ms\n",
      "Speed: 12.7ms preprocess, 117.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 truck, 113.7ms\n",
      "Speed: 0.0ms preprocess, 113.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 100.2ms\n",
      "Speed: 0.0ms preprocess, 100.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 116.6ms\n",
      "Speed: 0.0ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 100.2ms\n",
      "Speed: 0.0ms preprocess, 100.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 101.2ms\n",
      "Speed: 15.6ms preprocess, 101.2ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 stop sign, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 stop sign, 116.5ms\n",
      "Speed: 0.0ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 stop sign, 100.2ms\n",
      "Speed: 0.0ms preprocess, 100.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 stop sign, 116.8ms\n",
      "Speed: 0.0ms preprocess, 116.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "YOLO Detection Inference Time: 0.22 seconds per frame\n",
      "FASTER_RCCN Detection Inference Time: 3.45 seconds per frame\n",
      "SSD Detection Inference Time: 0.55 seconds per frame\n"
     ]
    }
   ],
   "source": [
    "# Measure inference time on a sample of frames from the video\n",
    "cap = cv2.VideoCapture(VIDEO)\n",
    "sample_frames = []\n",
    "for i in range(20):  # Change 10 to the number of frames you want to sample\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    sample_frames.append(frame)\n",
    "cap.release()\n",
    "\n",
    "# Measure performance\n",
    "models = [yolo_model, faster_rccn_model, ssd_model]\n",
    "types = ['yolo', 'faster_rccn', 'ssd']\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model_time, model_results = measure_performance(model=models[i], frames=sample_frames, model_type=types[i])\n",
    "    print(f'{types[i].upper()} Detection Inference Time: {model_time:.2f} seconds per frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPS (frames per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fps(model, video, model_type, num_frames=10):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open video\")\n",
    "        return None\n",
    "\n",
    "    frame_count = 0\n",
    "    total_time = 0\n",
    "\n",
    "    while frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_tensor = preprocess_frame(frame, model_type)\n",
    "        if model_type != 'yolo':\n",
    "            frame_tensor = frame_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            if model_type == 'yolo':\n",
    "                results = model(frame)\n",
    "            else:\n",
    "                results = model(frame_tensor)\n",
    "        end_time = time.time()\n",
    "        total_time += (end_time - start_time)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if frame_count > 0:\n",
    "        fps = frame_count / total_time\n",
    "        return fps\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 8 persons, 3 cars, 120.1ms\n",
      "Speed: 0.0ms preprocess, 120.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 117.1ms\n",
      "Speed: 5.0ms preprocess, 117.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 137.9ms\n",
      "Speed: 3.1ms preprocess, 137.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 117.9ms\n",
      "Speed: 15.6ms preprocess, 117.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 127.9ms\n",
      "Speed: 0.9ms preprocess, 127.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 120.9ms\n",
      "Speed: 3.4ms preprocess, 120.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 107.3ms\n",
      "Speed: 0.0ms preprocess, 107.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 108.4ms\n",
      "Speed: 1.0ms preprocess, 108.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 truck, 100.0ms\n",
      "Speed: 16.9ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 truck, 116.8ms\n",
      "Speed: 0.0ms preprocess, 116.8ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "YOLO Detection FPS: 7.69 frames per second\n",
      "FASTER RCCN Detection FPS: 0.30 frames per second\n",
      "SSD Detection FPS: 2.12 frames per second\n"
     ]
    }
   ],
   "source": [
    "# Calculate FPS\n",
    "models = [yolo_model, faster_rccn_model, ssd_model]\n",
    "types = ['yolo', 'faster rccn', 'ssd']\n",
    "\n",
    "for i in range(len(models)):    \n",
    "    fps = calculate_fps(model=models[i], video=VIDEO, num_frames=10, model_type=types[i])\n",
    "    if fps:\n",
    "        print(f'{types[i].upper()} Detection FPS: {fps:.2f} frames per second')\n",
    "    else:\n",
    "        print('Could not calculate FPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatim\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.7 🚀 Python-3.11.9 torch-2.1.2+cpu CPU (Intel Core(TM) i5-10300H 2.50GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.1.2+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 3.8s, saved as 'yolov8n.torchscript' (12.5 MB)\n",
      "\n",
      "Export complete (6.3s)\n",
      "Results saved to \u001b[1mC:\\ML\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.torchscript imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "YOLO model size: 12.47 MB\n",
      "Faster R-CNN model size: 159.79 MB\n",
      "SSD model size: 135.99 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "faster_rcnn_model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "ssd_model = ssd300_vgg16(pretrained=True)\n",
    "yolo_model = YOLO('yolov8n.pt').export()\n",
    "\n",
    "# Save the models\n",
    "torch.save(faster_rcnn_model.state_dict(), 'faster_rcnn_model.pth')\n",
    "torch.save(ssd_model.state_dict(), 'ssd_model.pth')\n",
    "\n",
    "# Get the file sizes\n",
    "yolo_size = os.path.getsize('yolov8n.torchscript') / (1024 * 1024)\n",
    "faster_rcnn_size = os.path.getsize('faster_rcnn_model.pth') / (1024 * 1024)  # in MB\n",
    "ssd_size = os.path.getsize('ssd_model.pth') / (1024 * 1024)  # in MB\n",
    "\n",
    "# Print\n",
    "print(f\"YOLO model size: {yolo_size:.2f} MB\")\n",
    "print(f\"Faster R-CNN model size: {faster_rcnn_size:.2f} MB\")\n",
    "print(f\"SSD model size: {ssd_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
